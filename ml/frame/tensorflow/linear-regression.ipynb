{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6639271  0.32152668 0.18041019 0.06583979 0.38375655 0.60111254\n",
      "  0.9965454  0.24070701 0.00564563 0.7955635  0.07626779 0.5496052\n",
      "  0.23850346 0.31537017 0.2853806  0.88060635 0.784949   0.83057487\n",
      "  0.21805468 0.5894747  0.18779771 0.96662074 0.684109   0.9084656\n",
      "  0.4958042  0.2053855  0.01463797 0.17240645 0.7617452  0.13472293\n",
      "  0.41126567 0.21372104 0.6513015  0.55149597 0.3110797  0.9492233\n",
      "  0.8632512  0.6488376  0.24962455 0.8495602  0.6576104  0.72040385\n",
      "  0.68296796 0.94061047 0.65413415 0.5637833  0.9457553  0.55804414\n",
      "  0.7879265  0.7995621  0.21191084 0.04924987 0.6849385  0.5992621\n",
      "  0.33543837 0.53433186 0.16551849 0.14886956 0.4029291  0.73855776\n",
      "  0.68508875 0.9055097  0.3371938  0.39251813 0.5035177  0.57765853\n",
      "  0.6893829  0.37745294 0.2151666  0.13620326 0.8548884  0.20948586\n",
      "  0.870436   0.62003636 0.03875645 0.3034616  0.58953714 0.8445257\n",
      "  0.3803837  0.12399821 0.49402368 0.39793852 0.529855   0.5095353\n",
      "  0.4147694  0.17973979 0.796969   0.93425375 0.6093201  0.47517362\n",
      "  0.89998835 0.56400675 0.89452726 0.87107915 0.1825446  0.316999\n",
      "  0.8397296  0.42412046 0.08558331 0.73225003]\n",
      " [0.15191376 0.73110443 0.08604504 0.8994671  0.9928552  0.8689691\n",
      "  0.61337703 0.4434999  0.4014038  0.6166879  0.94090694 0.34605068\n",
      "  0.94589645 0.81359696 0.24469985 0.39788333 0.9459759  0.19715121\n",
      "  0.15355594 0.28786567 0.84640056 0.6706776  0.36038962 0.7001119\n",
      "  0.5849205  0.75019187 0.6249041  0.20337291 0.8671379  0.6694461\n",
      "  0.38584375 0.01360181 0.01019871 0.36067373 0.09745196 0.23997596\n",
      "  0.6281633  0.59580594 0.35563505 0.21365763 0.762922   0.851352\n",
      "  0.9914506  0.32532457 0.24977577 0.15175036 0.16517653 0.5748308\n",
      "  0.03761465 0.95514315 0.7454681  0.5194216  0.22235171 0.6415454\n",
      "  0.88811076 0.18143725 0.98846906 0.60178024 0.5168144  0.93688387\n",
      "  0.18812111 0.47672388 0.53429896 0.7789608  0.13596253 0.7997086\n",
      "  0.17651708 0.5456569  0.21736138 0.5034686  0.21530566 0.8359959\n",
      "  0.8847011  0.06261523 0.35170013 0.3395842  0.41686064 0.20050491\n",
      "  0.90754026 0.8753531  0.712994   0.53022975 0.14138381 0.29019907\n",
      "  0.7587282  0.33830586 0.30585197 0.65012336 0.29177552 0.77356803\n",
      "  0.07108096 0.71730745 0.6612387  0.97568315 0.2396349  0.6675718\n",
      "  0.35520557 0.5282528  0.7438468  0.86517364]]\n",
      "[0.39677546 0.47837355 0.33525003 0.4864774  0.53694669 0.53390507\n",
      " 0.52232994 0.41277068 0.38084533 0.50289393 0.49580817 0.42417066\n",
      " 0.51302963 0.49425641 0.37747803 0.4676373  0.56769008 0.42248773\n",
      " 0.35251666 0.4165206  0.48805988 0.53079759 0.44048882 0.53086895\n",
      " 0.46656452 0.47057692 0.42644462 0.35791523 0.5496021  0.44736152\n",
      " 0.41829532 0.32409247 0.36716989 0.42728434 0.35059836 0.44291752\n",
      " 0.51195778 0.48404495 0.39608946 0.42768755 0.51834544 0.54231078\n",
      " 0.56658692 0.45912596 0.41536857 0.3867284  0.42761084 0.47077057\n",
      " 0.38631558 0.57098484 0.4702847  0.4088093  0.41296419 0.48823529\n",
      " 0.51116599 0.38972064 0.51424566 0.435243   0.44365579 0.56123255\n",
      " 0.4061331  0.48589575 0.44057917 0.49504398 0.37754427 0.51770757\n",
      " 0.40424171 0.44687668 0.36498893 0.41431404 0.42854997 0.48814777\n",
      " 0.56398382 0.37452668 0.37421567 0.398263   0.44232584 0.42455355\n",
      " 0.51954642 0.48747044 0.49200116 0.4458398  0.38126226 0.40899335\n",
      " 0.49322258 0.38563515 0.44086729 0.52345005 0.41928712 0.50223097\n",
      " 0.40421503 0.49986216 0.52170046 0.58224455 0.36618144 0.46521426\n",
      " 0.45501407 0.4480626  0.45732769 0.54625973]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.float32(np.random.rand(2,100))\n",
    "y_data = np.dot([0.100,0.200],x_data) + 0.300\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.zeros([1]))\n",
    "W = tf.Variable(tf.random_uniform([1,2],-1.0,1.0))\n",
    "y = tf.matmul(W,x_data) + b\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\python\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.87382627 -0.55972576]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.09996028 0.19996476]] [0.30004036]\n",
      "20 [[0.09998433 0.1999861 ]] [0.30001593]\n",
      "40 [[0.09999383 0.19999452]] [0.30000627]\n",
      "60 [[0.09999755 0.19999783]] [0.3000025]\n",
      "80 [[0.09999903 0.19999914]] [0.300001]\n",
      "100 [[0.09999959 0.19999966]] [0.3000004]\n",
      "120 [[0.09999985 0.19999987]] [0.30000016]\n",
      "140 [[0.09999988 0.19999988]] [0.30000013]\n",
      "160 [[0.09999988 0.19999988]] [0.30000013]\n",
      "180 [[0.09999988 0.19999988]] [0.30000013]\n",
      "200 [[0.09999988 0.19999988]] [0.30000013]\n",
      "220 [[0.09999988 0.19999988]] [0.30000013]\n",
      "240 [[0.09999988 0.19999988]] [0.30000013]\n",
      "260 [[0.09999988 0.19999988]] [0.30000013]\n",
      "280 [[0.09999988 0.19999988]] [0.30000013]\n",
      "300 [[0.09999988 0.19999988]] [0.30000013]\n",
      "320 [[0.09999988 0.19999988]] [0.30000013]\n",
      "340 [[0.09999988 0.19999988]] [0.30000013]\n",
      "360 [[0.09999988 0.19999988]] [0.30000013]\n",
      "380 [[0.09999988 0.19999988]] [0.30000013]\n",
      "400 [[0.09999988 0.19999988]] [0.30000013]\n",
      "420 [[0.09999988 0.19999988]] [0.30000013]\n",
      "440 [[0.09999988 0.19999988]] [0.30000013]\n",
      "460 [[0.09999988 0.19999988]] [0.30000013]\n",
      "480 [[0.09999988 0.19999988]] [0.30000013]\n",
      "500 [[0.09999988 0.19999988]] [0.30000013]\n",
      "520 [[0.09999988 0.19999988]] [0.30000013]\n",
      "540 [[0.09999988 0.19999988]] [0.30000013]\n",
      "560 [[0.09999988 0.19999988]] [0.30000013]\n",
      "580 [[0.09999988 0.19999988]] [0.30000013]\n",
      "600 [[0.09999988 0.19999988]] [0.30000013]\n",
      "620 [[0.09999988 0.19999988]] [0.30000013]\n",
      "640 [[0.09999988 0.19999988]] [0.30000013]\n",
      "660 [[0.09999988 0.19999988]] [0.30000013]\n",
      "680 [[0.09999988 0.19999988]] [0.30000013]\n",
      "700 [[0.09999988 0.19999988]] [0.30000013]\n",
      "720 [[0.09999988 0.19999988]] [0.30000013]\n",
      "740 [[0.09999988 0.19999988]] [0.30000013]\n",
      "760 [[0.09999988 0.19999988]] [0.30000013]\n",
      "780 [[0.09999988 0.19999988]] [0.30000013]\n",
      "800 [[0.09999988 0.19999988]] [0.30000013]\n",
      "820 [[0.09999988 0.19999988]] [0.30000013]\n",
      "840 [[0.09999988 0.19999988]] [0.30000013]\n",
      "860 [[0.09999988 0.19999988]] [0.30000013]\n",
      "880 [[0.09999988 0.19999988]] [0.30000013]\n",
      "900 [[0.09999988 0.19999988]] [0.30000013]\n",
      "920 [[0.09999988 0.19999988]] [0.30000013]\n",
      "940 [[0.09999988 0.19999988]] [0.30000013]\n",
      "960 [[0.09999988 0.19999988]] [0.30000013]\n",
      "980 [[0.09999988 0.19999988]] [0.30000013]\n",
      "1000 [[0.09999988 0.19999988]] [0.30000013]\n",
      "1020 [[0.09999988 0.19999988]] [0.30000013]\n",
      "1040 [[0.09999988 0.19999988]] [0.30000013]\n",
      "1060 [[0.09999988 0.19999988]] [0.30000013]\n",
      "1080 [[0.09999988 0.19999988]] [0.30000013]\n",
      "1100 [[0.09999988 0.19999988]] [0.30000013]\n"
     ]
    }
   ],
   "source": [
    "for step in range(0,1101):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step,sess.run(W),sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
